# CrimeAlytics
BDA 594 final project

### Objective

This project is centered around the comprehensive analysis of crime data originating from the cities of Chicago, Los Angeles, and San Francisco. 
Our primary focus involves the collection of diverse features related to criminal incidents. 
By delving into the historical crime data for these locations, we aim to conduct a thorough examination to discern patterns and insights. 
One key aspect of our investigation is to assess whether a committed crime can be successfully resolved, drawing valuable conclusions from the patterns observed in the historical crime data. 
This initiative is crucial for enhancing our understanding of crime dynamics in these urban areas and contributing to informed decision-making in law enforcement and public safety.

### Data Sources 
* Los Angeles: https://catalog.data.gov/dataset/crime-data-from-2010-to-2019 + https://catalog.data.gov/dataset/crime-data-from-2020-to-present
* San Francisco: https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-2018-to-Present/wg3w-h783/about_data
* Chicago: https://catalog.data.gov/dataset/crimes-2001-to-present

### Machine Learning Models
* XGBoost Algorithm
* Random forest Algorithm
* Logistic regression Algorithm

#### Website Link : https://sites.google.com/sdsu.edu/crime-alytics?usp=sharing
#### Streamlit App : https://crimealytics-bda594.streamlit.app/
<img width="1088" alt="Screenshot 2023-12-13 at 2 34 57 PM" src="https://github.com/ManishaMatta/CrimeAlytics/assets/50313389/0594a0da-aa69-46bc-9bd4-7d4c553bf1fe">
#### Tableau Dashboard : 


### Methodology
In this application we can consider data from 2017 to 2022 [published in 2023].
1. Data Preprocessing: Clean and preprocess the raw data, handling missing values, outliers, and ensuring data quality.
2. Exploratory Data Analysis (EDA): Conduct an in-depth exploration of the dataset to understand patterns, trends, and relationships.
3. Feature Engineering: Create meaningful features or variables that can enhance the predictive power of the model.
4. Algorithm Selection: Choose machine learning algorithms suitable for crime prediction tasks
5. Training: Train the selected model using historical crime data, optimizing model parameters for better performance.
6. Validation: Evaluate the model's performance using validation datasets, employing metrics like accuracy, precision, recall, and F1 score.
7. Hyperparameter Tuning: Fine-tune model parameters to enhance predictive accuracy.
8. Integration: Deploy the trained model into a production environment, integrating it with the existing crime analytics infrastructure.
9. Scalability: Ensure that the deployed model can handle real-time predictions and scale as the volume of data increases.
10. Performance Monitoring: Continuously monitor the model's performance to identify degradation and make necessary adjustments.
11. Model Updating: Periodically retrain the model with new data to adapt to evolving patterns and trends in crime.
12. Dashboard Creation: Develop interactive dashboards or visualization tools for law enforcement and analysts to interpret model predictions.
13. Reporting: Generate reports summarizing key findings, insights, and actionable recommendations.
14. Data Privacy: Implement measures to ensure the privacy and security of sensitive crime data.
15. Ethical Considerations: Address ethical concerns related to bias, fairness, and transparency in machine learning models.

